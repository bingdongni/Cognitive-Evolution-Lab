#!/usr/bin/env python3
"""
Cognitive Evolution Lab - å†…éƒ¨å¿ƒæ™ºæ¨¡å‹
ä½œè€…: bingdongni

å®ç°å†…éƒ¨å¿ƒæ™ºæ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼š
- è®°å¿†ç³»ç»Ÿï¼ˆæƒ…æ™¯ã€è¯­ä¹‰ã€ç¨‹åºè®°å¿†ï¼‰
- æ¨ç†ç³»ç»Ÿï¼ˆæ¼”ç»ã€å½’çº³ã€æº¯å› æ¨ç†ï¼‰
- æ³¨æ„åŠ›æœºåˆ¶ï¼ˆé€‰æ‹©æ€§ã€æŒç»­æ€§ã€åˆ†æ•£æ€§ï¼‰
- å­¦ä¹ æœºåˆ¶ï¼ˆå…ƒå­¦ä¹ ã€ç»ˆèº«å­¦ä¹ ï¼‰
- åˆ›é€ åŠ›æ¨¡å—
- è§‚å¯ŸåŠ›æ¨¡å—
- æƒ³è±¡åŠ›æ¨¡å—
"""

import asyncio
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from typing import Dict, List, Any, Optional, Tuple
import logging
from pathlib import Path
import json
import random
from dataclasses import dataclass, field
from enum import Enum
import pickle
from collections import deque, defaultdict
import math

# å¯¼å…¥Transformer
try:
    from transformers import AutoTokenizer, AutoModel
    TRANSFORMERS_AVè®¤çŸ¥è®¡ç®—LABLE = True
except ImportError:
    TRANSFORMERS_AVè®¤çŸ¥è®¡ç®—LABLE = False


class MemoryType(Enum):
    """è®°å¿†ç±»å‹æšä¸¾"""
    EPISODIC = "episodic"
    SEMANTIC = "semantic"
    PROCEDURAL = "procedural"
    WORKING = "working"


class ReasoningType(Enum):
    """æ¨ç†ç±»å‹æšä¸¾"""
    DEDUCTIVE = "deductive"    # æ¼”ç»æ¨ç†
    INDUCTIVE = "inductive"    # å½’çº³æ¨ç†
    ABDUCTIVE = "abductive"    # æº¯å› æ¨ç†
    ANALOGICAL = "analogical"  # ç±»æ¯”æ¨ç†


class AttentionType(Enum):
    """æ³¨æ„åŠ›ç±»å‹æšä¸¾"""
    SELECTIVE = "selective"    # é€‰æ‹©æ€§æ³¨æ„
    SUSTè®¤çŸ¥è®¡ç®—NED = "sustained"    # æŒç»­æ€§æ³¨æ„
    DIVIDED = "divided"        # åˆ†æ•£æ€§æ³¨æ„


@dataclass
class Memory:
    """è®°å¿†å•å…ƒ"""
    content: Any
    type: MemoryType
    strength: float
    timestamp: float
    associations: List[str] = field(default_factory=list)
    accessibility: float = 1.0


@dataclass
class CognitiveState:
    """è®¤çŸ¥çŠ¶æ€"""
    attention_focus: str
    working_memory: List[Any] = field(default_factory=list)
    current_goal: str = ""
    emotional_state: Dict[str, float] = field(default_factory=dict)
    cognitive_load: float = 0.0


@dataclass
class ReasoningChain:
    """æ¨ç†é“¾"""
    premises: List[str]
    conclusion: str
    confidence: float
    reasoning_type: ReasoningType
    steps: List[Dict[str, Any]]


class HierarchicalMemory(nn.Module):
    """å±‚æ¬¡è®°å¿†ç½‘ç»œ"""
    
    def __init__(self, vocab_size: int, embed_dim: int, hidden_dim: int, num_layers: int):
        super().__init__()
        self.embed_dim = embed_dim
        self.hidden_dim = hidden_dim
        
        # åµŒå…¥å±‚
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        
        # LSTMå±‚ï¼ˆç”¨äºåºåˆ—å¤„ç†ï¼‰
        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, 
                           batch_first=True, dropout=0.1)
        
        # æ³¨æ„åŠ›å±‚
        self.attention = nn.MultiheadAttention(hidden_dim, 8, dropout=0.1)
        
        # è®°å¿†èåˆå±‚
        self.memory_fusion = nn.Linear(hidden_dim * 2, hidden_dim)
        
        # è¾“å‡ºå±‚
        self.output_proj = nn.Linear(hidden_dim, hidden_dim)
    
    def forward(self, input_ids, memory_state=None):
        # åµŒå…¥
        embedded = self.embedding(input_ids)
        
        # LSTMå¤„ç†
        lstm_out, (hidden, cell) = self.lstm(embedded)
        
        # æ³¨æ„åŠ›æœºåˆ¶
        attention_out, attention_weights = self.attention(
            lstm_out, lstm_out, lstm_out
        )
        
        # è®°å¿†èåˆ
        if memory_state is not None:
            combined = torch.cat([attention_out, memory_state], dim=-1)
        else:
            combined = attention_out
        
        fused = torch.relu(self.memory_fusion(combined))
        output = self.output_proj(fused)
        
        return output, hidden, attention_weights


class AttentionMechanism(nn.Module):
    """æ³¨æ„åŠ›æœºåˆ¶æ¨¡å—"""
    
    def __init__(self, embed_dim: int, num_heads: int = 8, dropout: float = 0.1):
        super().__init__()
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        
        self.attention = nn.MultiheadAttention(
            embed_dim, num_heads, dropout=dropout, batch_first=True
        )
        
        self.norm = nn.LayerNorm(embed_dim)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, query, key, value, attention_mask=None):
        # å¤šå¤´æ³¨æ„åŠ›
        attended, attention_weights = self.attention(
            query, key, value, key_padding_mask=attention_mask
        )
        
        # æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–
        attended = self.norm(attended + self.dropout(attended))
        
        return attended, attention_weights


class NeuroSymbolicReasoner(nn.Module):
    """ç¥ç»ç¬¦å·æ¨ç†å™¨"""
    
    def __init__(self, symbol_dim: int, neural_dim: int, reasoning_steps: int = 5):
        super().__init__()
        self.symbol_dim = symbol_dim
        self.neural_dim = neural_dim
        self.reasoning_steps = reasoning_steps
        
        # ç¬¦å·ç¼–ç å™¨
        self.symbol_encoder = nn.Linear(1, symbol_dim)
        
        # ç¥ç»æ¨ç†ç½‘ç»œ
        self.neural_reasoner = nn.Sequential(
            nn.Linear(symbol_dim * 2, neural_dim),
            nn.ReLU(),
            nn.Linear(neural_dim, neural_dim),
            nn.ReLU(),
            nn.Linear(neural_dim, symbol_dim)
        )
        
        # ç¬¦å·è§£ç å™¨
        self.symbol_decoder = nn.Linear(symbol_dim, 1)
        
        # æ¨ç†æ­¥è¿›æ¨¡å—
        self.reasoning_steps_modules = nn.ModuleList([
            nn.Linear(symbol_dim * 2, symbol_dim) for _ in range(reasoning_steps)
        ])
    
    def forward(self, premise1, premise2, reasoning_type="deductive"):
        # ç¼–ç å‰æ
        s1 = torch.tanh(self.symbol_encoder(premise1))
        s2 = torch.tanh(self.symbol_encoder(premise2))
        
        # ç¥ç»ç¬¦å·æ¨ç†
        current_state = torch.cat([s1, s2], dim=-1)
        
        for i, step_module in enumerate(self.reasoning_steps_modules):
            step_input = torch.cat([current_state, s1], dim=-1) if reasoning_type == "inductive" else current_state
            step_output = torch.tanh(step_module(step_input))
            current_state = step_output
        
        # è§£ç ç»“è®º
        conclusion = torch.sigmoid(self.symbol_decoder(current_state))
        
        return conclusion
    
    def extract_symbolic_rules(self) -> Dict[str, Any]:
        """æå–ç¬¦å·è§„åˆ™"""
        rules = {}
        
        # ä»ç¥ç»ç½‘ç»œæƒé‡ä¸­æå–è§„åˆ™
        for name, param in self.named_parameters():
            if 'reasoning_steps' in name and param.grad is not None:
                # ç®€åŒ–çš„è§„åˆ™æå–
                rule_strength = torch.abs(param.mean()).item()
                if rule_strength > 0.1:
                    step_num = name.split('.')[1]
                    rules[f"rule_step_{step_num}"] = rule_strength
        
        return rules


class CreativityModule(nn.Module):
    """åˆ›é€ åŠ›æ¨¡å—"""
    
    def __init__(self, latent_dim: int, vocab_size: int, max_length: int = 100):
        super().__init__()
        self.latent_dim = latent_dim
        self.vocab_size = vocab_size
        self.max_length = max_length
        
        # æ½œåœ¨ç©ºé—´ç”Ÿæˆå™¨
        self.latent_generator = nn.Sequential(
            nn.Linear(latent_dim * 2, latent_dim * 2),
            nn.ReLU(),
            nn.Linear(latent_dim * 2, latent_dim),
            nn.Tanh()
        )
        
        # åˆ›æ„è§£ç å™¨
        self.creative_decoder = nn.LSTM(
            latent_dim, latent_dim, batch_first=True, dropout=0.1
        )
        
        # è¾“å‡ºæŠ•å½±
        self.output_proj = nn.Linear(latent_dim, vocab_size)
        
        # å‘æ•£æ€ç»´æ¨¡å—
        self.divergent_thinking = nn.Sequential(
            nn.Linear(latent_dim, latent_dim // 2),
            nn.ReLU(),
            nn.Linear(latent_dim // 2, latent_dim * 3)
        )
        
        # æ”¶æ•›æ€ç»´æ¨¡å—
        self.convergent_thinking = nn.Sequential(
            nn.Linear(latent_dim * 3, latent_dim),
            nn.ReLU(),
            nn.Linear(latent_dim, latent_dim),
            nn.Sigmoid()
        )
    
    def forward(self, context, style, temperature=1.0):
        # å‘æ•£æ€ç»´ - ç”Ÿæˆå¤šç§å¯èƒ½æ€§
        divergent_output = self.divergent_thinking(context)
        
        # é£æ ¼èåˆ
        style_expanded = style.expand_as(divergent_output)
        combined_features = torch.cat([divergent_output, style_expanded], dim=-1)
        
        # æ”¶æ•›æ€ç»´ - é€‰æ‹©æœ€ä½³åˆ›æ„
        convergent_output = self.convergent_thinking(combined_features)
        
        # åˆ›æ„ç”Ÿæˆ
        latent = self.latent_generator(convergent_output)
        
        # è§£ç åˆ›æ„
        hidden = latent.unsqueeze(0)
        outputs = []
        
        for t in range(self.max_length):
            lstm_out, hidden = self.creative_decoder(hidden, hidden)
            output = self.output_proj(lstm_out.squeeze(0))
            outputs.append(output)
            
            # é‡‡æ ·ï¼ˆæ¸©åº¦é‡‡æ ·ï¼‰
            logits = output / temperature
            probs = torch.softmax(logits, dim=-1)
            next_token = torch.multinomial(probs, 1)
            next_input = self.embed_token(next_token)
            hidden = next_input.unsqueeze(0)
        
        return torch.stack(outputs, dim=1)
    
    def embed_token(self, token):
        # ç®€åŒ–çš„tokenåµŒå…¥
        return torch.zeros_like(token.float())


class ObservationModule(nn.Module):
    """è§‚å¯ŸåŠ›æ¨¡å—"""
    
    def __init__(self, input_channels: int, feature_dim: int):
        super().__init__()
        self.input_channels = input_channels
        self.feature_dim = feature_dim
        
        # å¤šå°ºåº¦ç‰¹å¾æå–å™¨
        self.multi_scale_conv = nn.ModuleList([
            nn.Conv2d(input_channels, 32, kernel_size=3, padding=1),
            nn.Conv2d(32, 64, kernel_size=5, padding=2),
            nn.Conv2d(64, 128, kernel_size=7, padding=3)
        ])
        
        # æ¨¡å¼è¯†åˆ«ç½‘ç»œ
        self.pattern_recognizer = nn.Sequential(
            nn.AdaptiveAvgPool2d((8, 8)),
            nn.Flatten(),
            nn.Linear(128 * 8 * 8, 512),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(512, feature_dim)
        )
        
        # å¼‚å¸¸æ£€æµ‹å™¨
        self.anomaly_detector = nn.Sequential(
            nn.Linear(feature_dim, feature_dim // 2),
            nn.ReLU(),
            nn.Linear(feature_dim // 2, 1),
            nn.Sigmoid()
        )
        
        # æ—¶é—´æ¨¡å¼åˆ†æå™¨
        self.temporal_analyzer = nn.LSTM(
            feature_dim, feature_dim // 2, batch_first=True, dropout=0.1
        )
    
    def forward(self, observations, temporal_sequence=None):
        # å¤šå°ºåº¦ç‰¹å¾æå–
        features = observations
        multi_scale_features = []
        
        for conv_layer in self.multi_scale_conv:
            features = torch.relu(conv_layer(features))
            pooled = torch.mean(features, dim=[2, 3])  # å…¨å±€å¹³å‡æ± åŒ–
            multi_scale_features.append(pooled)
        
        # èåˆå¤šå°ºåº¦ç‰¹å¾
        combined_features = torch.cat(multi_scale_features, dim=-1)
        
        # æ¨¡å¼è¯†åˆ«
        pattern_features = self.pattern_recognizer(observations)
        
        # å¼‚å¸¸æ£€æµ‹
        anomaly_score = self.anomaly_detector(pattern_features)
        
        # æ—¶é—´åˆ†æ
        if temporal_sequence is not None:
            temporal_features, _ = self.temporal_analyzer(temporal_sequence)
            temporal_patterns = temporal_features[:, -1, :]
        else:
            temporal_patterns = torch.zeros_like(pattern_features)
        
        return {
            'pattern_features': pattern_features,
            'multi_scale_features': combined_features,
            'anomaly_score': anomaly_score,
            'temporal_patterns': temporal_patterns
        }


class MetaLearner(nn.Module):
    """å…ƒå­¦ä¹ å™¨"""
    
    def __init__(self, task_dim: int, adaptation_dim: int, meta_dim: int):
        super().__init__()
        self.task_dim = task_dim
        self.adaptation_dim = adaptation_dim
        self.meta_dim = meta_dim
        
        # ä»»åŠ¡ç¼–ç å™¨
        self.task_encoder = nn.Linear(task_dim, meta_dim)
        
        # å…ƒå‚æ•°ç”Ÿæˆå™¨
        self.meta_generator = nn.Sequential(
            nn.Linear(meta_dim * 2, meta_dim),
            nn.ReLU(),
            nn.Linear(meta_dim, adaptation_dim)
        )
        
        # é€‚åº”ç‡å­¦ä¹ å™¨
        self.adaptation_learner = nn.Sequential(
            nn.Linear(meta_dim, meta_dim // 2),
            nn.ReLU(),
            nn.Linear(meta_dim // 2, 1),
            nn.Sigmoid()
        )
        
        # è®°å¿†ç½‘ç»œ
        self.memory_network = nn.LSTM(
            meta_dim, meta_dim, batch_first=True, dropout=0.1
        )
    
    def forward(self, task_representations, adaptation_history=None):
        # ç¼–ç ä»»åŠ¡
        encoded_tasks = torch.tanh(self.task_encoder(task_representations))
        
        # å¦‚æœæœ‰å†å²é€‚åº”æ•°æ®
        if adaptation_history is not None:
            meta_memory, _ = self.memory_network(adaptation_history)
            meta_context = meta_memory[:, -1, :]
        else:
            meta_context = torch.zeros_like(encoded_tasks)
        
        # ç”Ÿæˆå…ƒå‚æ•°
        combined_meta = torch.cat([encoded_tasks, meta_context], dim=-1)
        meta_parameters = self.meta_generator(combined_meta)
        
        # å­¦ä¹ é€‚åº”ç‡
        adaptation_rate = self.adaptation_learner(encoded_tasks)
        
        return {
            'meta_parameters': meta_parameters,
            'adaptation_rate': adaptation_rate,
            'meta_context': meta_context
        }


class CognitiveAgent:
    """
    è®¤çŸ¥è®¤çŸ¥ä¸»ä½“ä¸»ç±»
    
    æ•´åˆæ‰€æœ‰è®¤çŸ¥èƒ½åŠ›ï¼š
    - è®°å¿†ç³»ç»Ÿ
    - æ¨ç†èƒ½åŠ›
    - æ³¨æ„åŠ›æœºåˆ¶
    - å­¦ä¹ èƒ½åŠ›
    - åˆ›é€ åŠ›
    - è§‚å¯ŸåŠ›
    - æƒ³è±¡åŠ›
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–è®¤çŸ¥è®¤çŸ¥ä¸»ä½“
        
        Args:
            config: è®¤çŸ¥æ¨¡å‹é…ç½®
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # åŸºç¡€é…ç½®
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.vocab_size = config.get('vocab_size', 10000)
        self.embed_dim = config.get('embed_dim', 512)
        self.hidden_dim = config.get('hidden_dim', 768)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.memory_system = None
        self.attention_mechanism = None
        self.reasoning_system = None
        self.creativity_module = None
        self.observation_module = None
        self.meta_learner = None
        
        # è®¤çŸ¥çŠ¶æ€
        self.cognitive_state = CognitiveState(
            attention_focus="default",
            current_goal="explore"
        )
        
        # è®°å¿†å­˜å‚¨
        self.memories = {
            MemoryType.EPISODIC: deque(maxlen=1000),
            MemoryType.SEMANTIC: deque(maxlen=500),
            MemoryType.PROCEDURAL: deque(maxlen=100),
            MemoryType.WORKING: deque(maxlen=10)
        }
        
        # æ¨ç†é“¾å­˜å‚¨
        self.reasoning_chains = deque(maxlen=200)
        
        # å­¦ä¹ å†å²
        self.learning_history = deque(maxlen=1000)
        
        # æ¨¡å‹å‚æ•°
        self.model_parameters = {}
        
        self.logger.info("ğŸ§  è®¤çŸ¥è®¤çŸ¥ä¸»ä½“åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize(self):
        """å¼‚æ­¥åˆå§‹åŒ–æ‰€æœ‰è®¤çŸ¥ç»„ä»¶"""
        self.logger.info("ğŸ”§ åˆå§‹åŒ–è®¤çŸ¥ç»„ä»¶...")
        
        try:
            # åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
            self.memory_system = HierarchicalMemory(
                vocab_size=self.vocab_size,
                embed_dim=self.embed_dim,
                hidden_dim=self.hidden_dim,
                num_layers=3
            ).to(self.device)
            
            # åˆå§‹åŒ–æ³¨æ„åŠ›æœºåˆ¶
            self.attention_mechanism = AttentionMechanism(
                embed_dim=self.embed_dim,
                num_heads=8,
                dropout=0.1
            ).to(self.device)
            
            # åˆå§‹åŒ–æ¨ç†ç³»ç»Ÿ
            self.reasoning_system = NeuroSymbolicReasoner(
                symbol_dim=self.embed_dim,
                neural_dim=self.hidden_dim,
                reasoning_steps=5
            ).to(self.device)
            
            # åˆå§‹åŒ–åˆ›é€ åŠ›æ¨¡å—
            self.creativity_module = CreativityModule(
                latent_dim=self.embed_dim,
                vocab_size=self.vocab_size,
                max_length=100
            ).to(self.device)
            
            # åˆå§‹åŒ–è§‚å¯ŸåŠ›æ¨¡å—
            self.observation_module = ObservationModule(
                input_channels=3,  # RGB
                feature_dim=self.embed_dim
            ).to(self.device)
            
            # åˆå§‹åŒ–å…ƒå­¦ä¹ å™¨
            self.meta_learner = MetaLearner(
                task_dim=self.embed_dim,
                adaptation_dim=self.embed_dim,
                meta_dim=self.hidden_dim
            ).to(self.device)
            
            self.logger.info("âœ… è®¤çŸ¥ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ è®¤çŸ¥ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def store_memory(self, content: Any, memory_type: MemoryType, strength: float = 1.0):
        """å­˜å‚¨è®°å¿†"""
        memory = Memory(
            content=content,
            type=memory_type,
            strength=strength,
            timestamp=self._get_timestamp(),
            associations=[]
        )
        
        # æ›´æ–°è®°å¿†å¼ºåº¦ï¼ˆæ ¹æ®ç±»å‹è°ƒæ•´ï¼‰
        if memory_type == MemoryType.WORKING:
            memory.strength *= 0.5
        elif memory_type == MemoryType.EPISODIC:
            memory.strength *= 0.8
        elif memory_type == MemoryType.SEMANTIC:
            memory.strength *= 1.2
        elif memory_type == MemoryType.PROCEDURAL:
            memory.strength *= 0.9
        
        self.memories[memory_type].append(memory)
        
        # æ›´æ–°å…³è”
        await self._update_associations(memory)
        
        # è®°å¿†è¡°é€€ï¼ˆé—å¿˜æ›²çº¿ï¼‰
        self._apply_forgetting_curve()
    
    async def retrieve_memory(self, query: Any, memory_type: MemoryType = None, 
                            threshold: float = 0.5) -> List[Memory]:
        """æ£€ç´¢è®°å¿†"""
        if memory_type:
            memory_pool = [self.memories[memory_type]]
        else:
            memory_pool = self.memories.values()
        
        retrieved_memories = []
        
        for memories in memory_pool:
            for memory in memories:
                similarity = self._calculate_memory_similarity(query, memory.content)
                if similarity >= threshold:
                    retrieved_memories.append((memory, similarity))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        retrieved_memories.sort(key=lambda x: x[1], reverse=True)
        
        # è¿”å›å‰10ä¸ªæœ€ç›¸ä¼¼çš„è®°å¿†
        return [mem for mem, sim in retrieved_memories[:10]]
    
    def _calculate_memory_similarity(self, query: Any, memory_content: Any) -> float:
        """è®¡ç®—è®°å¿†ç›¸ä¼¼åº¦"""
        # ç®€åŒ–çš„ç›¸ä¼¼åº¦è®¡ç®—
        if isinstance(query, str) and isinstance(memory_content, str):
            # æ–‡æœ¬ç›¸ä¼¼åº¦
            query_words = set(query.lower().split())
            memory_words = set(memory_content.lower().split())
            
            if not query_words or not memory_words:
                return 0.0
            
            intersection = len(query_words & memory_words)
            union = len(query_words | memory_words)
            
            return intersection / union if union > 0 else 0.0
        
        elif isinstance(query, (int, float)) and isinstance(memory_content, (int, float)):
            # æ•°å€¼ç›¸ä¼¼åº¦
            diff = abs(query - memory_content)
            return max(0, 1 - diff / max(abs(query), abs(memory_content), 1))
        
        else:
            # é»˜è®¤ç›¸ä¼¼åº¦
            return 1.0 if query == memory_content else 0.0
    
    async def _update_associations(self, new_memory: Memory):
        """æ›´æ–°è®°å¿†å…³è”"""
        # ä¸ºæ–°è®°å¿†å»ºç«‹å…³è”
        for memory_type, memories in self.memories.items():
            for existing_memory in memories:
                similarity = self._calculate_memory_similarity(
                    new_memory.content, existing_memory.content
                )
                if similarity > 0.3:
                    if existing_memory.id not in new_memory.associations:
                        new_memory.associations.append(existing_memory.id)
                    if new_memory.id not in existing_memory.associations:
                        existing_memory.associations.append(new_memory.id)
    
    def _apply_forgetting_curve(self):
        """åº”ç”¨é—å¿˜æ›²çº¿"""
        current_time = self._get_timestamp()
        
        for memory_type, memories in self.memories.items():
            for memory in list(memories):  # åˆ›å»ºå‰¯æœ¬ä»¥é¿å…ä¿®æ”¹æ—¶å‡ºé”™
                # è‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿
                time_diff = current_time - memory.timestamp
                half_life = self._get_half_life(memory_type)
                
                # é—å¿˜å‡½æ•°
                decay_rate = math.log(2) / half_life
                memory.strength *= math.exp(-decay_rate * time_diff)
                
                # ç§»é™¤è¿‡å¼±çš„è®°å¿†
                if memory.strength < 0.1:
                    memories.remove(memory)
    
    def _get_half_life(self, memory_type: MemoryType) -> float:
        """è·å–åŠè¡°æœŸ"""
        half_lives = {
            MemoryType.WORKING: 0.1,      # 10ç§’
            MemoryType.EPISODIC: 3600,    # 1å°æ—¶
            MemoryType.SEMANTIC: 86400,   # 1å¤©
            MemoryType.PROCEDURAL: 604800 # 1å‘¨
        }
        return half_lives.get(memory_type, 3600)
    
    async def reason(self, premises: List[str], reasoning_type: ReasoningType = ReasoningType.DEDUCTIVE) -> ReasoningChain:
        """æ‰§è¡Œæ¨ç†"""
        self.logger.info(f"ğŸ§© å¼€å§‹æ¨ç†: {reasoning_type.value}")
        
        # ç®€åŒ–çš„æ¨ç†å®ç°
        if reasoning_type == ReasoningType.DEDUCTIVE:
            conclusion = self._deductive_reasoning(premises)
        elif reasoning_type == ReasoningType.INDUCTIVE:
            conclusion = self._inductive_reasoning(premises)
        elif reasoning_type == ReasoningType.ABDUCTIVE:
            conclusion = self._abductive_reasoning(premises)
        else:
            conclusion = "æœªçŸ¥æ¨ç†ç»“æœ"
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._calculate_reasoning_confidence(premises, conclusion)
        
        reasoning_chain = ReasoningChain(
            premises=premises,
            conclusion=conclusion,
            confidence=confidence,
            reasoning_type=reasoning_type,
            steps=[]
        )
        
        self.reasoning_chains.append(reasoning_chain)
        
        self.logger.info(f"âœ… æ¨ç†å®Œæˆ: {conclusion} (ç½®ä¿¡åº¦: {confidence:.2f})")
        return reasoning_chain
    
    def _deductive_reasoning(self, premises: List[str]) -> str:
        """æ¼”ç»æ¨ç†"""
        # ç®€åŒ–çš„æ¼”ç»æ¨ç†
        if len(premises) >= 2:
            # ç®€å•çš„é€»è¾‘æ¨ç†
            if "æ‰€æœ‰" in premises[0] and "æ˜¯" in premises[0]:
                if premises[1].startswith("è¿™æ˜¯"):
                    subject = premises[1][3:].strip()
                    if subject in premises[0]:
                        return f"å› æ­¤ï¼Œè¿™æ˜¯ä¸€ä¸ª{subject}"
        
        return "æ¼”ç»æ¨ç†ç»“æœ"
    
    def _inductive_reasoning(self, premises: List[str]) -> str:
        """å½’çº³æ¨ç†"""
        # ç®€åŒ–çš„å½’çº³æ¨ç†
        observations = [p for p in premises if "è§‚å¯Ÿ" in p or "å‘ç°" in p]
        if observations:
            return "åŸºäºè§‚å¯Ÿï¼Œå¾—å‡ºä¸€èˆ¬æ€§ç»“è®º"
        return "å½’çº³æ¨ç†ç»“æœ"
    
    def _abductive_reasoning(self, premises: List[str]) -> str:
        """æº¯å› æ¨ç†"""
        # ç®€åŒ–çš„æº¯å› æ¨ç†
        if premises and "è§£é‡Š" in premises[0]:
            return "æœ€å¯èƒ½çš„è§£é‡Š"
        return "æº¯å› æ¨ç†ç»“æœ"
    
    def _calculate_reasoning_confidence(self, premises: List[str], conclusion: str) -> float:
        """è®¡ç®—æ¨ç†ç½®ä¿¡åº¦"""
        # åŸºäºå‰ææ•°é‡å’Œç»“è®ºè´¨é‡çš„ç®€åŒ–ç½®ä¿¡åº¦è®¡ç®—
        base_confidence = min(0.9, 0.5 + len(premises) * 0.1)
        
        # æ ¹æ®ç»“è®ºè´¨é‡è°ƒæ•´
        if conclusion and conclusion != "æ¨ç†ç»“æœ":
            quality_bonus = 0.2
        else:
            quality_bonus = 0.0
        
        return min(1.0, base_confidence + quality_bonus)
    
    async def focus_attention(self, target: Any, attention_type: AttentionType = AttentionType.SELECTIVE):
        """èšç„¦æ³¨æ„åŠ›"""
        self.cognitive_state.attention_focus = str(target)
        
        # æ¨¡æ‹Ÿæ³¨æ„åŠ›æƒé‡åˆ†é…
        attention_weights = await self._compute_attention_weights(target, attention_type)
        
        # æ›´æ–°å·¥ä½œè®°å¿†
        relevant_memories = await self.retrieve_memory(target, threshold=0.6)
        self.cognitive_state.working_memory = [mem.content for mem in relevant_memories[:5]]
        
        # æ›´æ–°è®¤çŸ¥è´Ÿè·
        self.cognitive_state.cognitive_load = len(self.cognitive_state.working_memory) / 10.0
        
        return attention_weights
    
    async def _compute_attention_weights(self, target: Any, attention_type: AttentionType) -> Dict[str, float]:
        """è®¡ç®—æ³¨æ„åŠ›æƒé‡"""
        weights = {}
        
        if attention_type == AttentionType.SELECTIVE:
            # é€‰æ‹©æ€§æ³¨æ„ - é«˜æƒé‡ç»™ç›¸å…³ç›®æ ‡
            weights['relevance'] = 0.8
            weights['novelty'] = 0.6
            weights['emotional'] = 0.5
        
        elif attention_type == AttentionType.SUSTè®¤çŸ¥è®¡ç®—NED:
            # æŒç»­æ€§æ³¨æ„ - ç¨³å®šæƒé‡
            weights['relevance'] = 0.7
            weights['stability'] = 0.8
            weights['persistence'] = 0.9
        
        elif attention_type == AttentionType.DIVIDED:
            # åˆ†æ•£æ€§æ³¨æ„ - æƒé‡åˆ†æ•£
            weights['relevance'] = 0.4
            weights['diversity'] = 0.7
            weights['balance'] = 0.8
        
        return weights
    
    async def adapt_learning(self, new_task: Any, performance_feedback: float):
        """é€‚åº”æ€§å­¦ä¹ """
        self.logger.info(f"ğŸ“š å¼€å§‹é€‚åº”æ€§å­¦ä¹ ï¼Œä»»åŠ¡: {new_task}")
        
        # æ›´æ–°å…ƒå­¦ä¹ å™¨
        task_representation = await self._encode_task(new_task)
        
        meta_output = self.meta_learner(task_representation)
        
        adaptation_rate = meta_output['adaptation_rate'].item()
        
        # åŸºäºåé¦ˆè°ƒæ•´å­¦ä¹ ç‡
        if performance_feedback < 0.5:
            # è¡¨ç°å·®ï¼Œå¢åŠ å­¦ä¹ å¼ºåº¦
            self.config['learning_rate'] *= (1 + adaptation_rate)
        else:
            # è¡¨ç°å¥½ï¼Œé™ä½å­¦ä¹ å¼ºåº¦
            self.config['learning_rate'] *= (1 - adaptation_rate * 0.5)
        
        # è®°å½•å­¦ä¹ å†å²
        learning_record = {
            'task': str(new_task),
            'performance': performance_feedback,
            'adaptation_rate': adaptation_rate,
            'learning_rate': self.config['learning_rate'],
            'timestamp': self._get_timestamp()
        }
        
        self.learning_history.append(learning_record)
        
        self.logger.info(f"âœ… é€‚åº”æ€§å­¦ä¹ å®Œæˆï¼Œæ–°å­¦ä¹ ç‡: {self.config['learning_rate']:.4f}")
    
    async def generate_creative_output(self, context: str, style: str = "original") -> Dict[str, Any]:
        """ç”Ÿæˆåˆ›æ„è¾“å‡º"""
        self.logger.info(f"ğŸ¨ å¼€å§‹åˆ›æ„ç”Ÿæˆï¼Œé£æ ¼: {style}")
        
        # ç¼–ç ä¸Šä¸‹æ–‡å’Œé£æ ¼
        context_encoding = await self._encode_text(context)
        style_encoding = await self._encode_text(style)
        
        # ç”Ÿæˆåˆ›æ„
        with torch.no_grad():
            creative_output = self.creativity_module(
                context=context_encoding,
                style=style_encoding,
                temperature=0.8
            )
        
        # è§£ç åˆ›æ„å†…å®¹
        creative_text = await self._decode_creative_output(creative_output)
        
        # è¯„ä¼°åˆ›é€ åŠ›
        creativity_score = await self._evaluate_creativity(creative_text, context)
        
        # å­˜å‚¨åˆ›æ„è®°å¿†
        await self.store_memory(
            content=f"åˆ›æ„: {creative_text}",
            memory_type=MemoryType.EPISODIC,
            strength=creativity_score
        )
        
        result = {
            'creative_text': creative_text,
            'creativity_score': creativity_score,
            'style': style,
            'context': context,
            'generation_time': self._get_timestamp()
        }
        
        self.logger.info(f"âœ… åˆ›æ„ç”Ÿæˆå®Œæˆï¼Œè¯„åˆ†: {creativity_score:.2f}")
        return result
    
    async def observe_environment(self, observations: torch.Tensor, temporal_data: torch.Tensor = None) -> Dict[str, Any]:
        """è§‚å¯Ÿç¯å¢ƒ"""
        observations = observations.to(self.device)
        
        # å¤šæ¨¡æ€è§‚å¯Ÿåˆ†æ
        observation_results = self.observation_module(observations, temporal_data)
        
        # æ›´æ–°è®¤çŸ¥çŠ¶æ€
        current_focus = observation_results['pattern_features']
        
        # æ£€æµ‹é‡è¦å˜åŒ–
        if observation_results['anomaly_score'] > 0.7:
            await self.focus_attention("anomaly_detected", AttentionType.SELECTIVE)
            await self.store_memory(
                content="æ£€æµ‹åˆ°ç¯å¢ƒå¼‚å¸¸",
                memory_type=MemoryType.EPISODIC,
                strength=observation_results['anomaly_score'].item()
            )
        
        # æ›´æ–°è§‚å¯ŸåŠ›è®°å¿†
        await self.store_memory(
            content=observation_results,
            memory_type=MemoryType.EPISODIC,
            strength=0.8
        )
        
        return {
            'pattern_features': observation_results['pattern_features'].cpu(),
            'anomaly_score': observation_results['anomaly_score'].cpu(),
            'temporal_patterns': observation_results['temporal_patterns'].cpu(),
            'attention_triggered': observation_results['anomaly_score'] > 0.7
        }
    
    async def imagine_scenario(self, context: str, constraints: List[str] = None) -> Dict[str, Any]:
        """æƒ³è±¡æƒ…æ™¯"""
        self.logger.info("ğŸŒŸ å¼€å§‹æƒ…æ™¯æƒ³è±¡")
        
        # æ£€ç´¢ç›¸å…³è®°å¿†
        relevant_memories = await self.retrieve_memory(context, threshold=0.5)
        
        # ç”Ÿæˆæƒ³è±¡åœºæ™¯
        imagination = {
            'context': context,
            'scenario_elements': [],
            'probabilities': [],
            'constraints': constraints or []
        }
        
        # åŸºäºè®°å¿†ç”Ÿæˆå¯èƒ½æ€§
        for memory in relevant_memories[:5]:
            scenario_element = await self._generate_scenario_element(memory.content, constraints)
            if scenario_element:
                imagination['scenario_elements'].append(scenario_element)
                imagination['probabilities'].append(0.7)  # ç®€åŒ–çš„æ¦‚ç‡
        
        # è¯„ä¼°æƒ³è±¡è´¨é‡
        imagination_quality = len(imagination['scenario_elements']) / 5.0
        
        # å­˜å‚¨æƒ³è±¡è®°å¿†
        await self.store_memory(
            content=imagination,
            memory_type=MemoryType.EPISODIC,
            strength=imagination_quality
        )
        
        self.logger.info(f"âœ… æƒ…æ™¯æƒ³è±¡å®Œæˆï¼Œç”Ÿæˆ{len(imagination['scenario_elements'])}ä¸ªå…ƒç´ ")
        return imagination
    
    async def run_cognitive_test(self, environment, test_type: str = "full") -> Dict[str, Any]:
        """è¿è¡Œè®¤çŸ¥èƒ½åŠ›æµ‹è¯•"""
        self.logger.info(f"ğŸ§  å¼€å§‹è®¤çŸ¥èƒ½åŠ›æµ‹è¯•: {test_type}")
        
        if test_type == "memory" or test_type == "full":
            memory_results = await self._test_memory_capabilities()
        else:
            memory_results = {}
        
        if test_type == "reasoning" or test_type == "full":
            reasoning_results = await self._test_reasoning_capabilities()
        else:
            reasoning_results = {}
        
        if test_type == "creativity" or test_type == "full":
            creativity_results = await self._test_creativity_capabilities()
        else:
            creativity_results = {}
        
        if test_type == "observation" or test_type == "full":
            observation_results = await self._test_observation_capabilities()
        else:
            observation_results = {}
        
        if test_type == "attention" or test_type == "full":
            attention_results = await self._test_attention_capabilities()
        else:
            attention_results = {}
        
        if test_type == "imagination" or test_type == "full":
            imagination_results = await self._test_imagination_capabilities()
        else:
            imagination_results = {}
        
        # è®¡ç®—ç»¼åˆè®¤çŸ¥è¯„åˆ†
        all_scores = []
        if memory_results:
            all_scores.append(memory_results.get('score', 0))
        if reasoning_results:
            all_scores.append(reasoning_results.get('score', 0))
        if creativity_results:
            all_scores.append(creativity_results.get('score', 0))
        if observation_results:
            all_scores.append(observation_results.get('score', 0))
        if attention_results:
            all_scores.append(attention_results.get('score', 0))
        if imagination_results:
            all_scores.append(imagination_results.get('score', 0))
        
        overall_score = sum(all_scores) / len(all_scores) if all_scores else 0.5
        
        results = {
            'memory': memory_results,
            'reasoning': reasoning_results,
            'creativity': creativity_results,
            'observation': observation_results,
            'attention': attention_results,
            'imagination': imagination_results,
            'overall_score': overall_score,
            'cognitive_state': {
                'attention_focus': self.cognitive_state.attention_focus,
                'cognitive_load': self.cognitive_state.cognitive_load,
                'working_memory_size': len(self.cognitive_state.working_memory)
            },
            'test_type': test_type,
            'timestamp': self._get_timestamp()
        }
        
        self.logger.info(f"âœ… è®¤çŸ¥èƒ½åŠ›æµ‹è¯•å®Œæˆï¼Œæ€»ä½“è¯„åˆ†: {overall_score:.2f}")
        return results
    
    async def _test_memory_capabilities(self) -> Dict[str, Any]:
        """æµ‹è¯•è®°å¿†èƒ½åŠ›"""
        # å­˜å‚¨æµ‹è¯•è®°å¿†
        test_memories = ["è®°å¿†æµ‹è¯•1", "è®°å¿†æµ‹è¯•2", "è®°å¿†æµ‹è¯•3"]
        for memory in test_memories:
            await self.store_memory(memory, MemoryType.EPISODIC)
        
        # æ£€ç´¢æµ‹è¯•
        retrieved = await self.retrieve_memory("æµ‹è¯•", threshold=0.3)
        
        # è®¡ç®—è®°å¿†å‡†ç¡®ç‡
        accuracy = len(retrieved) / len(test_memories) if test_memories else 0
        
        return {
            'score': min(1.0, accuracy),
            'accuracy': accuracy,
            'retrieved_count': len(retrieved),
            'total_stored': len(test_memories)
        }
    
    async def _test_reasoning_capabilities(self) -> Dict[str, Any]:
        """æµ‹è¯•æ¨ç†èƒ½åŠ›"""
        test_cases = [
            (["æ‰€æœ‰é¸Ÿä¼šé£", "ä¼é¹…æ˜¯é¸Ÿ"], ReasoningType.DEDUCTIVE),
            (["è§‚å¯Ÿåˆ°å¤©é¹…1æ˜¯ç™½çš„", "è§‚å¯Ÿåˆ°å¤©é¹…2æ˜¯ç™½çš„"], ReasoningType.INDUCTIVE),
            (["è‰æ˜¯æ¹¿çš„"], ReasoningType.ABDUCTIVE)
        ]
        
        correct_reasoning = 0
        total_reasoning = len(test_cases)
        
        for premises, reasoning_type in test_cases:
            reasoning_chain = await self.reason(premises, reasoning_type)
            if reasoning_chain.confidence > 0.5:
                correct_reasoning += 1
        
        accuracy = correct_reasoning / total_reasoning
        
        return {
            'score': accuracy,
            'accuracy': accuracy,
            'correct_reasoning': correct_reasoning,
            'total_reasoning': total_reasoning
        }
    
    async def _test_creativity_capabilities(self) -> Dict[str, Any]:
        """æµ‹è¯•åˆ›é€ åŠ›èƒ½åŠ›"""
        creative_output = await self.generate_creative_output(
            context="è®¾è®¡ä¸€ä¸ªæ–°äº§å“",
            style="åˆ›æ–°"
        )
        
        creativity_score = creative_output['creativity_score']
        
        return {
            'score': creativity_score,
            'creativity_score': creativity_score,
            'creative_text': creative_output['creative_text']
        }
    
    async def _test_observation_capabilities(self) -> Dict[str, Any]:
        """æµ‹è¯•è§‚å¯Ÿèƒ½åŠ›"""
        # åˆ›å»ºæ¨¡æ‹Ÿè§‚å¯Ÿæ•°æ®
        mock_observations = torch.randn(1, 3, 224, 224)
        
        observation_results = await self.observe_environment(mock_observations)
        
        anomaly_score = observation_results['anomaly_score'].item()
        
        return {
            'score': 1.0 - anomaly_score,  # è¶Šå°‘å¼‚å¸¸ï¼Œè§‚å¯ŸåŠ›è¶Šå¥½
            'anomaly_score': anomaly_score,
            'pattern_recognition': "æˆåŠŸ"
        }
    
    async def _test_attention_capabilities(self) -> Dict[str, Any]:
        """æµ‹è¯•æ³¨æ„åŠ›èƒ½åŠ›"""
        attention_weights = await self.focus_attention("æµ‹è¯•ç›®æ ‡", AttentionType.SELECTIVE)
        
        # è®¡ç®—æ³¨æ„åŠ›é›†ä¸­åº¦
        concentration_score = attention_weights.get('relevance', 0.5)
        
        return {
            'score': concentration_score,
            'attention_weights': attention_weights,
            'concentration_score': concentration_score
        }
    
    async def _test_imagination_capabilities(self) -> Dict[str, Any]:
        """æµ‹è¯•æƒ³è±¡åŠ›èƒ½åŠ›"""
        imagination = await self.imagine_scenario(
            context="æœªæ¥ä¸–ç•Œ",
            constraints=["å¯æŒç»­", "æŠ€æœ¯å…ˆè¿›"]
        )
        
        # æƒ³è±¡åŠ›è¯„åˆ†åŸºäºç”Ÿæˆå…ƒç´ æ•°é‡
        imagination_score = len(imagination['scenario_elements']) / 5.0
        
        return {
            'score': imagination_score,
            'scenario_elements': len(imagination['scenario_elements']),
            'max_elements': 5
        }
    
    async def _encode_text(self, text: str) -> torch.Tensor:
        """ç¼–ç æ–‡æœ¬"""
        # ç®€åŒ–çš„æ–‡æœ¬ç¼–ç 
        tokens = text.split()
        encoding = torch.zeros(1, self.embed_dim)
        
        for token in tokens:
            # ç®€å•çš„å“ˆå¸Œç¼–ç 
            token_hash = hash(token) % self.vocab_size
            encoding[0, token_hash % self.embed_dim] += 1.0
        
        return encoding.to(self.device)
    
    async def _decode_creative_output(self, creative_output: torch.Tensor) -> str:
        """è§£ç åˆ›æ„è¾“å‡º"""
        # ç®€åŒ–çš„è§£ç 
        return "è¿™æ˜¯ä¸€ä¸ªåˆ›æ„ç”Ÿæˆçš„ç»“æœ"
    
    async def _evaluate_creativity(self, creative_text: str, context: str) -> float:
        """è¯„ä¼°åˆ›é€ åŠ›"""
        # åŸºäºæ–°é¢–æ€§å’Œç›¸å…³æ€§çš„ç®€åŒ–è¯„ä¼°
        novelty_score = random.uniform(0.3, 0.9)
        relevance_score = random.uniform(0.4, 0.8)
        
        return (novelty_score + relevance_score) / 2
    
    async def _encode_task(self, task: Any) -> torch.Tensor:
        """ç¼–ç ä»»åŠ¡"""
        task_str = str(task)
        return await self._encode_text(task_str)
    
    async def _generate_scenario_element(self, memory_content: Any, constraints: List[str]) -> Optional[str]:
        """ç”Ÿæˆåœºæ™¯å…ƒç´ """
        # ç®€åŒ–çš„åœºæ™¯å…ƒç´ ç”Ÿæˆ
        if constraints:
            for constraint in constraints:
                if constraint.lower() in str(memory_content).lower():
                    return f"ç¬¦åˆçº¦æŸ{constraint}çš„åœºæ™¯"
        
        return f"åŸºäºè®°å¿†çš„åœºæ™¯å…ƒç´ "
    
    def _get_timestamp(self) -> float:
        """è·å–æ—¶é—´æˆ³"""
        import time
        return time.time()
    
    async def test_memory_retention(self) -> Dict[str, Any]:
        """æµ‹è¯•è®°å¿†ä¿ç•™"""
        # æ£€ç´¢æ‰€æœ‰ç±»å‹çš„è®°å¿†
        retention_scores = {}
        
        for memory_type, memories in self.memories.items():
            if memories:
                total_strength = sum(memory.strength for memory in memories)
                avg_strength = total_strength / len(memories)
                retention_scores[memory_type.value] = avg_strength
            else:
                retention_scores[memory_type.value] = 0.0
        
        overall_retention = sum(retention_scores.values()) / len(retention_scores)
        
        return {
            'retention_scores': retention_scores,
            'retention_score': overall_retention,
            'timestamp': self._get_timestamp()
        }
    
    async def test_transfer_learning(self) -> Dict[str, Any]:
        """æµ‹è¯•è¿ç§»å­¦ä¹ """
        # æ¨¡æ‹Ÿè¿ç§»å­¦ä¹ æµ‹è¯•
        source_performance = 0.8
        target_performance = 0.6
        
        transfer_score = min(1.0, target_performance / source_performance)
        
        return {
            'transfer_score': transfer_score,
            'source_performance': source_performance,
            'target_performance': target_performance,
            'timestamp': self._get_timestamp()
        }
    
    async def analyze_learning_strategy(self) -> Dict[str, Any]:
        """åˆ†æå­¦ä¹ ç­–ç•¥"""
        if not self.learning_history:
            return {'strategy_analysis': 'æ— å­¦ä¹ å†å²'}
        
        recent_performances = [record['performance'] for record in list(self.learning_history)[-10:]]
        avg_performance = sum(recent_performances) / len(recent_performances)
        
        strategy_type = "exploratory" if avg_performance < 0.6 else "exploitative"
        
        return {
            'strategy_type': strategy_type,
            'avg_performance': avg_performance,
            'exploration_ratio': 0.3 if strategy_type == "exploratory" else 0.1,
            'adaptation_rate': np.mean([record['adaptation_rate'] for record in list(self.learning_history)[-5:]]),
            'timestamp': self._get_timestamp()
        }
    
    async def retrain_with_evolution(self, evolution_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºè¿›åŒ–æ•°æ®é‡æ–°è®­ç»ƒ"""
        self.logger.info("ğŸ§¬ åŸºäºè¿›åŒ–æ•°æ®é‡è®­ç»ƒ")
        
        # æå–æœ€ä¼˜ç‰¹å¾
        best_fitness = evolution_data.get('final_fitness', 0.5)
        
        # è°ƒæ•´å­¦ä¹ å‚æ•°
        improvement_factor = best_fitness / 0.5  # ç›¸å¯¹äºåŸºçº¿
        self.config['learning_rate'] *= improvement_factor
        
        # è®°å½•é‡è®­ç»ƒç»“æœ
        retrain_result = {
            'improvement_score': improvement_factor,
            'best_fitness': best_fitness,
            'new_learning_rate': self.config['learning_rate'],
            'retraining_success': improvement_factor > 1.0,
            'timestamp': self._get_timestamp()
        }
        
        self.logger.info(f"âœ… é‡è®­ç»ƒå®Œæˆï¼Œæ”¹è¿›åˆ†æ•°: {improvement_factor:.2f}")
        return retrain_result
    
    async def evaluate_individual(self, individual: Any, environment) -> Dict[str, Any]:
        """è¯„ä¼°ä¸ªä½“è®¤çŸ¥èƒ½åŠ›"""
        # ä¸ºç‰¹å®šä¸ªä½“åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
        test_environment = await self.create_individual_test_environment(individual)
        
        # è¿è¡Œå…¨é¢è®¤çŸ¥æµ‹è¯•
        cognitive_results = await self.run_cognitive_test(test_environment, "full")
        
        return {
            'cognitive_assessment': cognitive_results,
            'individual_id': str(individual),
            'overall_score': cognitive_results['overall_score'],
            'timestamp': self._get_timestamp()
        }
    
    async def create_individual_test_environment(self, individual: Any):
        """ä¸ºä¸ªä½“åˆ›å»ºæµ‹è¯•ç¯å¢ƒ"""
        # ç®€åŒ–çš„ä¸ªä½“æµ‹è¯•ç¯å¢ƒ
        class IndividualTestEnvironment:
            def __init__(self, individual):
                self.individual = individual
            
            async def get_test_data(self):
                return {'individual_data': str(individual)}
        
        return IndividualTestEnvironment(individual)
    
    def get_cognitive_metrics(self) -> Dict[str, Any]:
        """è·å–è®¤çŸ¥æŒ‡æ ‡"""
        return {
            'memory_counts': {mem_type.value: len(memories) 
                            for mem_type, memories in self.memories.items()},
            'reasoning_chains': len(self.reasoning_chains),
            'learning_history': len(self.learning_history),
            'current_cognitive_load': self.cognitive_state.cognitive_load,
            'attention_focus': self.cognitive_state.attention_focus
        }
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.logger.info("ğŸ§¹ æ¸…ç†è®¤çŸ¥è®¤çŸ¥ä¸»ä½“èµ„æº...")
        
        # æ¸…ç©ºè®°å¿†
        for memory_type in self.memories:
            self.memories[memory_type].clear()
        
        # æ¸…ç©ºæ¨ç†é“¾
        self.reasoning_chains.clear()
        
        # æ¸…ç©ºå­¦ä¹ å†å²
        self.learning_history.clear()
        
        # é‡Šæ”¾æ¨¡å‹å†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        self.logger.info("âœ… è®¤çŸ¥è®¤çŸ¥ä¸»ä½“èµ„æºæ¸…ç†å®Œæˆ")